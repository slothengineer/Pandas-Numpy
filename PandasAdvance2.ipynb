{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66b1325-e125-43a7-81c8-5ea50455537f",
   "metadata": {},
   "source": [
    "# Pandas Advance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470e4dc-fc1b-44c4-b07e-7f1415c5f79b",
   "metadata": {},
   "source": [
    "### Consider following code to answer further questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9934d8c2-a16c-499c-bc5b-a3fb592083fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b0492-b4aa-4c09-98d3-c53ad2164a8e",
   "metadata": {},
   "source": [
    "### 1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349620fb-3860-4ae1-86d9-847d200e5cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "# Code to print data in the second row\n",
    "second_row_data = df.iloc[1]\n",
    "print(second_row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d751cf8-91f2-4cb4-9eaf-0456fc8312fc",
   "metadata": {},
   "source": [
    "### 2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7241f8-c9c2-4327-89ac-0643a6c50eaf",
   "metadata": {},
   "source": [
    "The `loc` and `iloc` functions in pandas are used for selecting data from a DataFrame, but they differ in the way they handle indexing:\n",
    "\n",
    "1. **`loc`:**\n",
    "   - `loc` is label-based indexing, meaning that you use labels (either index labels or column labels) to select data.\n",
    "   - It includes the last element of the range specified.\n",
    "   - The syntax is `df.loc[row_label, column_label]` or `df.loc[row_label_range, column_label_range]`.\n",
    "   - Example: `df.loc[1, 'course_name']` selects the value in the 'course_name' column for the row with the index label 1.\n",
    "\n",
    "2. **`iloc`:**\n",
    "   - `iloc` is integer-location based indexing, meaning that you use integer indices to select data.\n",
    "   - It does not include the last element of the range specified.\n",
    "   - The syntax is `df.iloc[row_index, column_index]` or `df.iloc[row_index_range, column_index_range]`.\n",
    "   - Example: `df.iloc[1, 0]` selects the value in the first column for the second row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d425a424-3532-47a1-9858-ebff6374ed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loc:\n",
      "Machine Learning\n",
      "\n",
      "Using iloc:\n",
      "Machine Learning\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "# Using loc\n",
    "print(\"Using loc:\")\n",
    "print(df.loc[1, 'course_name'])  # Selects 'Machine Learning'\n",
    "\n",
    "# Using iloc\n",
    "print(\"\\nUsing iloc:\")\n",
    "print(df.iloc[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336cba5-a7c8-4fbf-b5a9-0151f8e9c9aa",
   "metadata": {},
   "source": [
    "In this example, both `loc` and `iloc` are used to select the value in the 'course_name' column for the second row, but they differ in their syntax and the type of indices they use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6851a-a9fb-49e4-8462-aa309e692c8b",
   "metadata": {},
   "source": [
    "### 3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df then find the output for both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be06b291-ca9b-45f1-90e6-ec5bbf25bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new_df.loc[2]:\n",
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Using new_df.iloc[2]:\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "# Reindexing using the provided order\n",
    "reindex_order = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex_order)\n",
    "\n",
    "# Output for new_df.loc[2]\n",
    "print(\"Using new_df.loc[2]:\")\n",
    "print(new_df.loc[2])\n",
    "\n",
    "# Output for new_df.iloc[2]\n",
    "print(\"\\nUsing new_df.iloc[2]:\")\n",
    "print(new_df.iloc[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3a19e-5f33-465b-887c-9f88b1846e9a",
   "metadata": {},
   "source": [
    "There is a difference in both outputs, and it's due to the reindexing operation. Let me explain:\n",
    "\n",
    "1. **`new_df.loc[2]`:**\n",
    "   - This uses label-based indexing. In the original DataFrame (`df`), the label 2 corresponds to the third row, which has the 'Big Data' course and a duration of 6. However, after reindexing with the order [3, 0, 1, 2], the label 2 now corresponds to the row with the 'Big Data' course and a duration of 6.\n",
    "\n",
    "2. **`new_df.iloc[2]`:**\n",
    "   - This uses integer-location based indexing. In the original DataFrame (`df`), the integer location 2 corresponds to the third row. After reindexing with the order [3, 0, 1, 2], the integer location 2 still corresponds to the third row, but now it has the 'Data Engineer' course and a duration of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6c24f-9aa4-4ea9-89d7-367acbaa21db",
   "metadata": {},
   "source": [
    "### Consider the below code to answer further questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d28fcb2-34c8-4a1d-9b20-3b58ec438d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b525f-f9d9-40a4-b482-7bfe41bb4424",
   "metadata": {},
   "source": [
    "### 4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75448484-55da-4cd6-b3ee-bc1f1dddf384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.692626\n",
      "column_2    0.490113\n",
      "column_3    0.415998\n",
      "column_4    0.394527\n",
      "column_5    0.284260\n",
      "column_6    0.376792\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of 'column_2':\n",
      "0.29998285040982636\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a dataframe\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# (i) Mean of each column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n",
    "# (ii) Standard deviation of column 'column_2'\n",
    "std_column_2 = df1['column_2'].std()\n",
    "print(\"\\nStandard Deviation of 'column_2':\")\n",
    "print(std_column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72d03f-ce88-4f4b-aa33-cdcf48949015",
   "metadata": {},
   "source": [
    "### 5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the mean of column, column_2.\n",
    "\n",
    "If you are getting errors in executing it then explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47aba0b8-ff27-43bc-9f92-85ccbc8678fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m replacement_string\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m after replacement:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a dataframe\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string\n",
    "replacement_string = 'StringData'\n",
    "df1.loc[2, 'column_2'] = replacement_string\n",
    "\n",
    "# Calculate the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of 'column_2' after replacement:\", mean_column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc1b07c-88bb-48fd-8ca3-bc2a7139e0c2",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "If you replace numerical data with a string and then try to calculate the mean of that column, you will encounter a TypeError. The mean operation cannot be performed on a column that contains both numeric and non-numeric data.\n",
    "\n",
    "If you want to replace the data in a numeric column with a string and still calculate the mean, you would need to convert the entire column to a data type that can handle both numeric and string values, such as object dtype (using astype('object')). Keep in mind that this approach may not be suitable for all use cases, as it involves working with mixed data types in a numeric column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e3068-e255-451c-b541-9f5121ba5407",
   "metadata": {},
   "source": [
    "### 6. What do you understand about the windows function in pandas and list the types of windowsfunctions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5d967-7790-43af-b767-7da8827c5c09",
   "metadata": {},
   "source": [
    "In pandas, window functions, also known as rolling or moving functions, are used for calculating aggregates over a specified window of rows in a DataFrame. These functions are particularly useful for time series data or any data where the order of the rows matters. Window functions operate on a defined window of consecutive rows and perform calculations such as mean, sum, standard deviation, etc., within that window.\n",
    "\n",
    "The primary window functions in pandas include:\n",
    "\n",
    "1. **`rolling()` Function:**\n",
    "   - This function is used to create a Rolling object for a DataFrame or Series.\n",
    "   - It takes the window size as a parameter, specifying the number of consecutive rows to include in each window.\n",
    "   - Common parameters include `window` (size of the window), `min_periods` (minimum number of observations in a window required to have a value), and others.\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   df['column'].rolling(window=3).mean()\n",
    "   ```\n",
    "\n",
    "2. **`expanding()` Function:**\n",
    "   - Similar to `rolling()`, the `expanding()` function creates an Expanding object.\n",
    "   - It considers all rows from the beginning of the DataFrame up to the current row in each calculation.\n",
    "   - Useful for calculating cumulative metrics.\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   df['column'].expanding().sum()\n",
    "   ```\n",
    "\n",
    "3. **`ewm()` Function (Exponentially Weighted Moving Average):**\n",
    "   - This function is used for exponentially weighted moving averages.\n",
    "   - It assigns exponentially decreasing weights to the observations based on their age.\n",
    "   - Parameters include `span`, `halflife`, and `alpha` to control the decay factor.\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   df['column'].ewm(span=3).mean()\n",
    "   ```\n",
    "\n",
    "These window functions enable efficient and flexible analysis of data trends and patterns over time, allowing for the calculation of aggregated statistics within a moving or expanding window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b949e-596e-4c2d-8f3f-a358954c3744",
   "metadata": {},
   "source": [
    "### 7. Write a code to print only the current month and year at the time of answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77c86c0-d57b-4732-885b-99279436509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month and Year: November 2023\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Format and print the current month and year\n",
    "formatted_date = current_date.strftime('%B %Y')\n",
    "print(\"Current Month and Year:\", formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f9067-e91c-4aea-a78b-d3afe1a6a7e8",
   "metadata": {},
   "source": [
    "### 8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and calculates the difference between them in days, hours, and minutes using Pandas time delta. The program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91a5b2e4-fe80-46d0-960c-171d01696cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  1998-05-11\n",
      "Enter the second date (YYYY-MM-DD):  1999-12-24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Difference:\n",
      "Days: 592\n",
      "Hours: 0\n",
      "Minutes: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate the difference between two dates\n",
    "def calculate_time_difference(date1, date2):\n",
    "    # Convert input strings to datetime objects\n",
    "    date1 = pd.to_datetime(date1)\n",
    "    date2 = pd.to_datetime(date2)\n",
    "\n",
    "    # Calculate the time difference\n",
    "    time_difference = date2 - date1\n",
    "\n",
    "    # Extract days, hours, and minutes\n",
    "    days = time_difference.days\n",
    "    hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "    minutes, _ = divmod(remainder, 60)\n",
    "\n",
    "    return days, hours, minutes\n",
    "\n",
    "# Get user input for two dates\n",
    "date_input1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date_input2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Calculate the time difference\n",
    "days_diff, hours_diff, minutes_diff = calculate_time_difference(date_input1, date_input2)\n",
    "\n",
    "# Display the result\n",
    "print(f\"\\nTime Difference:\\nDays: {days_diff}\\nHours: {hours_diff}\\nMinutes: {minutes_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ecd96-38e1-4cec-8327-7b3032666273",
   "metadata": {},
   "source": [
    "### 9. Write a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program should prompt the user to enter the file path, column name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75572758-c100-4566-b839-e1a66b61fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_categorical(file_path, column_name, category_order):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert the specified column to categorical\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "    # Display the sorted data\n",
    "    sorted_data = df.sort_values(by=[column_name])\n",
    "    print(\"\\nSorted Data:\")\n",
    "    print(sorted_data)\n",
    "\n",
    "# Get user input for file path, column name, and category order\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "\n",
    "# Prompt user for category order (comma-separated)\n",
    "category_order_input = input(\"Enter the category order (comma-separated): \")\n",
    "category_order = [category.strip() for category in category_order_input.split(',')]\n",
    "\n",
    "# Call the function to convert and display\n",
    "convert_to_categorical(file_path, column_name, category_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56b117-7dce-44aa-ad31-9b470909f237",
   "metadata": {},
   "source": [
    "### 10. Write a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913b461-8ab1-4ebd-8b57-74eb58c5e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sales_data(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert 'Date' to datetime for proper plotting\n",
    "    df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'], errors='coerce')\n",
    "\n",
    "    # Pivot the DataFrame to create a table suitable for plotting\n",
    "    sales_pivot = df.pivot(index='ORDERDATE', columns='QUANTITYORDERED', values='SALES').fillna(0)\n",
    "\n",
    "    # Plotting a stacked bar chart\n",
    "    sales_pivot.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.title('Stacked Bar Chart of Sales by Product Category Over Time')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Get user input for the CSV file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Call the function to visualize sales data\n",
    "visualize_sales_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540c373-622e-4a9a-af46-1ab3cec14d9a",
   "metadata": {},
   "source": [
    "### 11. You are given a CSV file containing student data that includes the student ID and their test score. Write a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and displays the results in a table.\n",
    "The program should do the followingM\n",
    "- Prompt the user to enter the file path of the CSV file containing the student data\n",
    "- Read the CSV file into a Pandas DataFrame\n",
    "- Calculate the mean, median, and mode of the test scores using Pandas tools\n",
    "- Display the mean, median, and mode in a table.\n",
    "\n",
    "Assume the CSV file contains the following columns\n",
    "- Student ID: The ID of the studentR\n",
    "- Test Score: The score of the student's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35742256-274d-4512-90cd-21f50fdda5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file containing the student data:  stud.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-----------+--------+\n",
      "| Statistic | Value  |\n",
      "+-----------+--------+\n",
      "| Mean      |   73.6 |\n",
      "| Median    |   75.5 |\n",
      "| Mode      | 85     |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_statistics(file_path):\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate mean, median, and mode\n",
    "    mean_score = df['marks'].mean()\n",
    "    median_score = df['marks'].median()\n",
    "    mode_scores = df['marks'].mode()\n",
    "\n",
    "    # Display the results in a table\n",
    "    results_table = pd.DataFrame({\n",
    "        'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "        'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]\n",
    "    })\n",
    "\n",
    "    print(\"\\n+-----------+--------+\")\n",
    "    print(\"| Statistic | Value  |\")\n",
    "    print(\"+-----------+--------+\")\n",
    "    for _, row in results_table.iterrows():\n",
    "        print(f\"| {row['Statistic']:9} | {row['Value']:6} |\")\n",
    "    print(\"+-----------+--------+\")\n",
    "\n",
    "# Get user input for the CSV file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# Call the function to calculate and display statistics\n",
    "calculate_statistics(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9254f-103b-43e9-8b2b-34ac95b3f8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
